{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d895d4",
   "metadata": {},
   "source": [
    "# Project: Sentiment detection\n",
    "\n",
    "- Date: July 25 2025 - break - August 5 2025\n",
    "\n",
    "- Data: We download the data with this command: wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip and then we decompressed it. This data contains 1,600,000 lines (text or tweet).\n",
    "\n",
    "- Description: In this project, we will build a model able to predict the feeling or sentiment expressed in a tweet( positif or negatif)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b954d87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa8152",
   "metadata": {},
   "source": [
    "# Downloading and cleaning of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8fc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "df_train = pd.read_csv(\"./data/training.1600000.processed.noemoticon.csv\",\n",
    "                        encoding='ISO-8859-1',\n",
    "                        header=None,\n",
    "                        names=['target','id','date','flag','user','text'])\n",
    "\n",
    "df_train= df_train[[\"target\",\"text\"]] # we keep only the targets and their texts\n",
    "df_train['target'] = df_train['target'].map({0:0, 4:1}) # Change the 0 and 4 into 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c1f6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1          is upset that he can't update his Facebook by ...\n",
      "2          @Kenichan I dived many times for the ball. Man...\n",
      "3            my whole body feels itchy and like its on fire \n",
      "4          @nationwideclass no, it's not behaving at all....\n",
      "                                 ...                        \n",
      "1599995    Just woke up. Having no school is the best fee...\n",
      "1599996    TheWDB.com - Very cool to hear old Walt interv...\n",
      "1599997    Are you ready for your MoJo Makeover? Ask me f...\n",
      "1599998    Happy 38th Birthday to my boo of alll time!!! ...\n",
      "1599999    happy #charitytuesday @theNSPCC @SparksCharity...\n",
      "Name: text, Length: 1600000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39cd93",
   "metadata": {},
   "source": [
    "After seeing some texts, I'm not very sure of the feeling given to the text in the target part but... let's do it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ece55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def text_preprocessing_nltk(text):\n",
    "    tokens=[]\n",
    "    stop_words=set(stopwords.words(\"english\")) # all stopword in english(\"the\", \"of\", \"is\",...)\n",
    "    stemming=PorterStemmer()\n",
    "\n",
    "    text=text.lower() #conversion in lowercase\n",
    "    text=re.sub(pattern=r'[^\\w\\s]', repl= '', string=text) # remove all special characters and keep only letters and numbers\n",
    "    text=re.sub(pattern=r'\\S+@\\S+',repl=' ', string=text) # Change of all emails by a space\n",
    "    text=re.sub(pattern=r'http:\\S+|www\\.\\S+', repl=' ',string=text) #Change all links or URL by space\n",
    "\n",
    "    #Tokenization\n",
    "    tokens=word_tokenize(text)\n",
    "\n",
    "    #Suppresion of stopwords\n",
    "    tokens=[word for word in tokens if word not in stop_words]\n",
    "\n",
    "    #Stemming\n",
    "    tokens=[stemming.stem(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#Definition of the vetorizer, the features and target\n",
    "vectorizer=TfidfVectorizer(preprocessor=text_preprocessing_nltk,\n",
    "                        tokenizer= lambda txt: txt.split())\n",
    "X=vectorizer.fit_transform(df_train['text'])\n",
    "y=df_train['target'].values\n",
    "\n",
    "#Note to myself: Search after what is really a pipepline and how to do it, cause it seems easier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf92ce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(df_train['target'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd232378",
   "metadata": {},
   "source": [
    "Now we have cleaned the data and split it into features and target let build our models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff04ef",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Our goal here is to predict if a message or a text has a good feeling or not ( 1 or 0). So we're going to use classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3150b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #Despite his name it is for classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd3ce256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Logisitc Regression==\n",
      "\t Accuracy score:  0.783453125\n",
      "\t Precision score:  0.7694629456885335\n",
      "\t Recall score:  0.8094125\n",
      "\t F1 score :  0.7889323103071211\n",
      "==Naive Bayes==\n",
      "\t Accuracy score:  0.75935\n",
      "\t Precision score:  0.7829439921449903\n",
      "\t Recall score:  0.71765625\n",
      "\t F1 score :  0.7488798596482075\n"
     ]
    }
   ],
   "source": [
    "#splitting the data\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y,test_size=0.2,\n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y)\n",
    "# train = 1 600 000*80% =  1 280 000\n",
    "# test = 1 600 000*20%= 320 000\n",
    "\n",
    "#Building models and training\n",
    "log_model=LogisticRegression().fit(X_train, y_train)\n",
    "nb_model=MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "#Predictions\n",
    "log_pred = log_model.predict(X_test)\n",
    "nb_pred  = nb_model.predict(X_test)\n",
    "\n",
    "#Evaluation\n",
    "def evaluate(model,y_true, y_pred):\n",
    "    print(f\"=={model}==\")\n",
    "    print(\"\\t Accuracy score: \", accuracy_score(y_true, y_pred))\n",
    "    print(\"\\t Precision score: \", precision_score(y_true, y_pred))\n",
    "    print(\"\\t Recall score: \", recall_score(y_true, y_pred))\n",
    "    print(\"\\t F1 score : \", f1_score(y_true, y_pred))\n",
    "\n",
    "evaluate(\"Logisitc Regression\", y_test, log_pred)\n",
    "evaluate(\"Naive Bayes\", y_test, nb_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4bb0a",
   "metadata": {},
   "source": [
    "We can notice that the accuracy, the precision and the F1 score are approximatly the same for this 2 models. And we can notice a bigger difference on thre recall score, it's mean the Logistic regression manage better to predict the good(1) tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf782f",
   "metadata": {},
   "source": [
    "Now we will take the best model amoung the model or algorithm made here and try to build a better one , more trained using the cross validation to increase is evalation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d692c32",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "So here we will train the models using cross validation algorithm. We don't really find the fact to use a stratify k fold useful because for me, whatever the case our model must be able to decide (regardless the other text) if a text has a good felling or not. But ...\n",
    "\n",
    "Also we will choose the metric f1_score because we find the precison and the recall very important, si taking a metric which is based on both seem suitable for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d049039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "===Logistic Regression Model===\n",
      "\tFit time by fold: [27.30670953 59.36786914 37.95665884 60.02354431 39.00714755]\n",
      "\tScore time by fold : [0.09246063 0.08748221 0.08915782 0.0947628  0.08222151]\n",
      "\tScore by fold: [0.09246063 0.08748221 0.08915782 0.0947628  0.08222151]\n",
      "\tMean of scores:  0.08921699523925782\n",
      "===Naive Bayes Model===\n",
      "\tFit time by fold: [0.52549553 0.51467371 0.59553051 0.51238537 0.54161119]\n",
      "\tScore time by fold : [0.09839749 0.11704421 0.10127902 0.12599659 0.14350796]\n",
      "\tScore by fold: [0.09839749 0.11704421 0.10127902 0.12599659 0.14350796]\n",
      "\tMean of scores:  0.11724505424499512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "\n",
    "cv=StratifiedKFold(n_splits=5,random_state=0,shuffle=True)\n",
    "\n",
    "nb_scores=cross_validate(nb_model,X,y,cv=cv,scoring='f1')\n",
    "log_scores=cross_validate(log_model,X,y,cv=cv,scoring=\"f1\")\n",
    "print(\" \")\n",
    "\n",
    "print(\"===Logistic Regression Model===\")\n",
    "print(\"\\tFit time by fold:\", log_scores[\"fit_time\"])\n",
    "print(\"\\tScore time by fold :\",log_scores[\"score_time\"])\n",
    "print(\"\\tScore by fold:\", log_scores[\"score_time\"])\n",
    "print(\"\\tMean of scores: \",log_scores[\"score_time\"].mean())\n",
    "\n",
    "print(\"===Naive Bayes Model===\")\n",
    "print(\"\\tFit time by fold:\", nb_scores[\"fit_time\"])\n",
    "print(\"\\tScore time by fold :\",nb_scores[\"score_time\"])\n",
    "print(\"\\tScore by fold:\", nb_scores[\"score_time\"])\n",
    "print(\"\\tMean of scores: \",nb_scores[\"score_time\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd26f4",
   "metadata": {},
   "source": [
    "We can notice that the mean of score is very very low in both case. But this is not really a big problem cause it is a little bit normal. In fact, we divided the dataset so we have less data in each group, what make it difficult for the model to be trained very well and have good result on the over part of the data. But globaly our models could be well trained.\n",
    "\n",
    "Let's see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9c1ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([27.30670953, 59.36786914, 37.95665884, 60.02354431, 39.00714755]), 'score_time': array([0.09246063, 0.08748221, 0.08915782, 0.0947628 , 0.08222151]), 'test_score': array([0.78765576, 0.7878557 , 0.78892763, 0.78665638, 0.78735007])}\n"
     ]
    }
   ],
   "source": [
    "#Just to see what is truly in the log_score and his type.\n",
    "print(log_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc53195",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Now we will test the models we trained on a new data to see their 'true' performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5688d0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Logistic Regression==\n",
      "\t Accuracy score:  0.807799442896936\n",
      "\t Precision score:  0.8021390374331551\n",
      "\t Recall score:  0.8241758241758241\n",
      "\t F1 score :  0.8130081300813008\n",
      "==Naive Bayes==\n",
      "\t Accuracy score:  0.7855153203342619\n",
      "\t Precision score:  0.8387096774193549\n",
      "\t Recall score:  0.7142857142857143\n",
      "\t F1 score :  0.771513353115727\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "df_test=pd.read_csv(\"/home/christian/ProjetsPerso/IA/MachineLearning/Sentiment_Detection/data/testdata.manual.2009.06.14.csv\",\n",
    "                        encoding='ISO-8859-1',\n",
    "                        header=None,\n",
    "                        names=['target','id','date','flag','user','text'])\n",
    "df_test= df_test[[\"target\",\"text\"]] # we keep only the targets and their texts\n",
    "df_test = df_test[df_test['target'].isin([0,4])].copy() # we lay the neutral tweet\n",
    "df_test['target'] = df_test['target'].map({0:0, 4:1}) # Change the 0 and 4 into 0 and 1\n",
    "\n",
    "\n",
    "#definitions of the features and targets\n",
    "#very important to have \"transform\" and not \"fit_transform\" cause the vacabulary already learned\n",
    "X_test=vectorizer.transform(df_test[\"text\"])  \n",
    "y_test=df_test['target'].values\n",
    "\n",
    "#predictions\n",
    "log_pred_test=log_model.predict(X_test)\n",
    "nb_pred_test=nb_model.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "evaluate(\"Logistic Regression\", y_test, log_pred_test)\n",
    "evaluate(\"Naive Bayes\", y_test, nb_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb7c67",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efc0b72",
   "metadata": {},
   "source": [
    "We can notice that the Logistic Regression model have a better score in every metric than the Naive Bayes one. Also despite some very bad scores in the cross validation, the models manage to predict correctly the target in the test.\n",
    "\n",
    "This project helps to revise principally the task of cleaning the data for learning tasks. We also learn that having bad scores in cross validation doesn't mean everytimes having a bad model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c52bc2e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
