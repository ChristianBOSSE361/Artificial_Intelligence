{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d895d4",
   "metadata": {},
   "source": [
    "# Project: Sentiment detection\n",
    "\n",
    "- Date: July 25 2025 - break - August 5 2025\n",
    "\n",
    "- Data: We download the data with this command: wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip and then we decompressed it.\n",
    "\n",
    "- Description: In this project, we will build a model able to predict the feeling or sentiment of express in a tweet( positif or negatif)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b954d87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa8152",
   "metadata": {},
   "source": [
    "# Downloading and cleaning of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c8fc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "df_train = pd.read_csv(\"./data/training.1600000.processed.noemoticon.csv\",\n",
    "                        encoding='ISO-8859-1',\n",
    "                        header=None,\n",
    "                        names=['target','id','date','flag','user','text'])\n",
    "\n",
    "df_train= df_train[[\"target\",\"text\"]] # we keep only the targets and their texts\n",
    "df_train['target'] = df_train['target'].map({0:0, 4:1}) # Change the 0 and 4 into 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44c1f6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1          is upset that he can't update his Facebook by ...\n",
      "2          @Kenichan I dived many times for the ball. Man...\n",
      "3            my whole body feels itchy and like its on fire \n",
      "4          @nationwideclass no, it's not behaving at all....\n",
      "                                 ...                        \n",
      "1599995    Just woke up. Having no school is the best fee...\n",
      "1599996    TheWDB.com - Very cool to hear old Walt interv...\n",
      "1599997    Are you ready for your MoJo Makeover? Ask me f...\n",
      "1599998    Happy 38th Birthday to my boo of alll time!!! ...\n",
      "1599999    happy #charitytuesday @theNSPCC @SparksCharity...\n",
      "Name: text, Length: 1600000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39cd93",
   "metadata": {},
   "source": [
    "After seeing some texts, I'm not very sure of the feeling the target give them but... let's do it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36ece55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def text_preprocessing_nltk(text):\n",
    "    tokens=[]\n",
    "    stop_words=set(stopwords.words(\"english\")) # all stopword in english(\"the\", \"of\", \"is\",...)\n",
    "    stemming=PorterStemmer()\n",
    "\n",
    "    text=text.lower() #conversion in lowercase\n",
    "    text=re.sub(pattern=r'[^\\w\\s]', repl= '', string=text) # remove all special characters and keep only letters and numbers\n",
    "    text=re.sub(pattern=r'\\S+@\\S+',repl=' ', string=text) # Change of all emails by a space\n",
    "    text=re.sub(pattern=r'http:\\S+|www\\.\\S+', repl=' ',string=text) #Change all links or URL by space\n",
    "\n",
    "    #Tokenization\n",
    "    tokens=word_tokenize(text)\n",
    "\n",
    "    #Suppresion of stopwords\n",
    "    tokens=[word for word in tokens if word not in stop_words]\n",
    "\n",
    "    #Stemming\n",
    "    tokens=[stemming.stem(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#Definition of the vetorizer, the features and target\n",
    "vectorizer=TfidfVectorizer(preprocessor=text_preprocessing_nltk,\n",
    "                        tokenizer= lambda txt: txt.split())\n",
    "X=vectorizer.fit_transform(df_train['text'])\n",
    "y=df_train['target'].values\n",
    "\n",
    "#search after what is a pipepline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf92ce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(df_train['target'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd232378",
   "metadata": {},
   "source": [
    "Now we have cleaned the data and split it into features and target let build our models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff04ef",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Our goal here is to predict if a message or a text has a good feeling or not ( 1 or 0), so we're going to use classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3150b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6874b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd3ce256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Logisitc Regression==\n",
      "\t Accuracy score:  0.783453125\n",
      "\t Precision score:  0.7694629456885335\n",
      "\t Recall score:  0.8094125\n",
      "\t F1 score :  0.7889323103071211\n",
      "==Naive Bayes==\n",
      "\t Accuracy score:  0.75935\n",
      "\t Precision score:  0.7829439921449903\n",
      "\t Recall score:  0.71765625\n",
      "\t F1 score :  0.7488798596482075\n"
     ]
    }
   ],
   "source": [
    "#splitting the data\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y,test_size=0.2,\n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y)\n",
    "# train = 1 600 000*80% =  1 280 000\n",
    "# test = 1 600 000*20%= 320 000\n",
    "\n",
    "#Building models and training\n",
    "log_model=LogisticRegression().fit(X_train, y_train)\n",
    "nb_model=MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "#Predictions\n",
    "log_pred = log_model.predict(X_test)\n",
    "nb_pred  = nb_model.predict(X_test)\n",
    "\n",
    "#Evaluation\n",
    "def evaluate(model,y_true, y_pred):\n",
    "    print(f\"=={model}==\")\n",
    "    print(\"\\t Accuracy score: \", accuracy_score(y_true, y_pred))\n",
    "    print(\"\\t Precision score: \", precision_score(y_true, y_pred))\n",
    "    print(\"\\t Recall score: \", recall_score(y_true, y_pred))\n",
    "    print(\"\\t F1 score : \", f1_score(y_true, y_pred))\n",
    "\n",
    "evaluate(\"Logisitc Regression\", y_test, log_pred)\n",
    "evaluate(\"Naive Bayes\", y_test, nb_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4bb0a",
   "metadata": {},
   "source": [
    "We can notice that the accuracy, the precision and the F1 score are approximatly the same for this 2 models. And we can notice a bigger difference on thre recall score, it's mean the Logistic regression manage better to predict the good(1) tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf782f",
   "metadata": {},
   "source": [
    "Now we will take the best model amoung the model or algorithm made here and try to build a better one , more trained using the cross validation to increase is evalation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d692c32",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "So here we will train the models using cross validation algorithm. We don't find the fact to use a stratify k fold useful because whatever the case our model must be able to decide (regardless the other text) if a text has a good felling or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d049039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "===Logistic Regression Model===\n",
      "\tFit time by fold: [23.6139667  49.31603146 31.73586297 46.12800837 31.16413713]\n",
      "\tScore time by fold : [0.07994699 0.07846737 0.0738287  0.0804739  0.07032108]\n",
      "\tScore by fold: [0.07994699 0.07846737 0.0738287  0.0804739  0.07032108]\n",
      "\tMean of scores:  0.07660760879516601\n",
      "===Naive Bayes Model===\n",
      "\tFit time by fold: [0.35080838 0.3566885  0.3486321  0.3446641  0.34824872]\n",
      "\tScore time by fold : [0.07740021 0.08381534 0.0763495  0.07897806 0.07797885]\n",
      "\tScore by fold: [0.07740021 0.08381534 0.0763495  0.07897806 0.07797885]\n",
      "\tMean of scores:  0.07890439033508301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "\n",
    "cv=StratifiedKFold(n_splits=5,random_state=0,shuffle=True)\n",
    "\n",
    "nb_scores=cross_validate(nb_model,X,y,cv=cv,scoring='f1')\n",
    "log_scores=cross_validate(log_model,X,y,cv=cv,scoring=\"f1\")\n",
    "print(\" \")\n",
    "\n",
    "print(\"===Logistic Regression Model===\")\n",
    "print(\"\\tFit time by fold:\", log_scores[\"fit_time\"])\n",
    "print(\"\\tScore time by fold :\",log_scores[\"score_time\"])\n",
    "print(\"\\tScore by fold:\", log_scores[\"score_time\"])\n",
    "print(\"\\tMean of scores: \",log_scores[\"score_time\"].mean())\n",
    "\n",
    "print(\"===Naive Bayes Model===\")\n",
    "print(\"\\tFit time by fold:\", nb_scores[\"fit_time\"])\n",
    "print(\"\\tScore time by fold :\",nb_scores[\"score_time\"])\n",
    "print(\"\\tScore by fold:\", nb_scores[\"score_time\"])\n",
    "print(\"\\tMean of scores: \",nb_scores[\"score_time\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9c1ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([23.6139667 , 49.31603146, 31.73586297, 46.12800837, 31.16413713]), 'score_time': array([0.07994699, 0.07846737, 0.0738287 , 0.0804739 , 0.07032108]), 'test_score': array([0.78765576, 0.7878557 , 0.78892763, 0.78665638, 0.78735007])}\n"
     ]
    }
   ],
   "source": [
    "print(log_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc53195",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Now we will test on a new data to see the true performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688d0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Logistic Regression==\n",
      "\t Accuracy score:  0.807799442896936\n",
      "\t Precision score:  0.8021390374331551\n",
      "\t Recall score:  0.8241758241758241\n",
      "\t F1 score :  0.8130081300813008\n",
      "==Naive Bayes==\n",
      "\t Accuracy score:  0.7855153203342619\n",
      "\t Precision score:  0.8387096774193549\n",
      "\t Recall score:  0.7142857142857143\n",
      "\t F1 score :  0.771513353115727\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "df_test=pd.read_csv(\"/home/christian/ProjetsPerso/IA/MachineLearning/Sentiment_Detection/data/testdata.manual.2009.06.14.csv\",\n",
    "                        encoding='ISO-8859-1',\n",
    "                        header=None,\n",
    "                        names=['target','id','date','flag','user','text'])\n",
    "df_test= df_test[[\"target\",\"text\"]] # we keep only the targets and their texts\n",
    "df_test = df_test[df_test['target'].isin([0,4])].copy() # we lay the neutral tweet\n",
    "df_test['target'] = df_test['target'].map({0:0, 4:1}) # Change the 0 and 4 into 0 and 1\n",
    "\n",
    "\n",
    "#definitions of the features and targets\n",
    "#very important to have \"transform\" and not \"fit_transform\" cause the vacabulary already learned\n",
    "X_test=vectorizer.transform(df_test[\"text\"])  \n",
    "y_test=df_test['target'].values\n",
    "\n",
    "#predictions\n",
    "log_pred_test=log_model.predict(X_test)\n",
    "nb_pred_test=nb_model.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "evaluate(\"Logistic Regression\", y_test, log_pred_test)\n",
    "evaluate(\"Naive Bayes\", y_test, nb_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb7c67",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efc0b72",
   "metadata": {},
   "source": [
    "We can notice that the Logistic Regression model have a better score in every metric than the Naive Bayes one. Also despite some very bad scores in the cross validation, the models manage to predict correctly the target in the test. Why?\n",
    "\n",
    "This project helps to revise principally the task of cleaning the data for learning taaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c52bc2e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
